{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taniyathakur45/tree_species_classification/blob/main/tree_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_HLBUKhUARH",
        "outputId": "a48ae634-97c5-475b-8a50-a472f20b4d76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tree_Species_Dataset'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/kailas93/Tree-Species-Identification.git Tree_Species_Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "AIVeoK8SKlud",
        "outputId": "51ec2b1f-bbf3-4ba4-c9ac-f004b1d43c1c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Tree_Species_Dataset'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-10-65007096.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrepo_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Tree_Species_Dataset\"\u001b[0m  \u001b[0;31m# Adjust if cloned to a different name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Contents:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Tree_Species_Dataset'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "repo_path = \"Tree_Species_Dataset\"  # Adjust if cloned to a different name\n",
        "print(\"Contents:\", os.listdir(repo_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Egd3Sg_JLDUY"
      },
      "outputs": [],
      "source": [
        "class_dirs = os.listdir(repo_path)\n",
        "print(f\"Number of classes: {len(class_dirs)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6fKLdxvLXmg"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "for class_name in os.listdir(repo_path):\n",
        "    class_folder = os.path.join(repo_path, class_name)\n",
        "    if os.path.isdir(class_folder):\n",
        "        for img_file in os.listdir(class_folder):\n",
        "            image_paths.append(os.path.join(class_folder, img_file))\n",
        "            labels.append(class_name)\n",
        "\n",
        "print(f\"Total images: {len(image_paths)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiB7A6TNL0np"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "class_counts = {cls: len(os.listdir(os.path.join(repo_path, cls))) for cls in class_dirs}\n",
        "class_counts_df = pd.DataFrame.from_dict(class_counts, orient='index', columns=['Image Count'])\n",
        "print(class_counts_df.sort_values('Image Count', ascending=False).head())\n",
        "print(\"shape: \",class_counts_df.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fucq9x6MJVB"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "def show_sample_images(repo_path, class_dirs, n=5):\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, class_dir in enumerate(class_dirs[:n]):\n",
        "        img_path = os.path.join(repo_path, class_dir, os.listdir(os.path.join(repo_path, class_dir))[0])\n",
        "        img = Image.open(img_path)\n",
        "        plt.subplot(1, n, i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(class_dir)\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "show_sample_images(repo_path, class_dirs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBS0zLf4M4Gu"
      },
      "outputs": [],
      "source": [
        "image_shapes = []\n",
        "\n",
        "for class_dir in class_dirs:\n",
        "    for img_file in os.listdir(os.path.join(repo_path, class_dir)):\n",
        "        img_path = os.path.join(repo_path, class_dir, img_file)\n",
        "        img = Image.open(img_path)\n",
        "        image_shapes.append(img.size)\n",
        "\n",
        "# DataFrame and Summary\n",
        "import pandas as pd\n",
        "\n",
        "shapes_df = pd.DataFrame(image_shapes, columns=[\"Width\", \"Height\"])\n",
        "shapes_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWQFf0u9NEM-"
      },
      "outputs": [],
      "source": [
        "print(shapes_df.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0e3JPGBGNQ-R"
      },
      "outputs": [],
      "source": [
        "import hashlib\n",
        "from collections import defaultdict\n",
        "\n",
        "hashes = defaultdict(list)\n",
        "\n",
        "for class_dir in class_dirs:\n",
        "    for img_file in os.listdir(os.path.join(repo_path, class_dir)):\n",
        "        img_path = os.path.join(repo_path, class_dir, img_file)\n",
        "        with open(img_path, 'rb') as f:\n",
        "            file_hash = hashlib.md5(f.read()).hexdigest()\n",
        "            hashes[file_hash].append(img_path)\n",
        "\n",
        "# Filter duplicates\n",
        "duplicates = {h: files for h, files in hashes.items() if len(files) > 1}\n",
        "print(\"Duplicate image sets found:\", len(duplicates))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_UHi_IuNggv"
      },
      "outputs": [],
      "source": [
        "corrupt_images = []\n",
        "\n",
        "for class_dir in class_dirs:\n",
        "    for img_file in os.listdir(os.path.join(repo_path, class_dir)):\n",
        "        img_path = os.path.join(repo_path, class_dir, img_file)\n",
        "        try:\n",
        "            img = Image.open(img_path)\n",
        "            img.verify()\n",
        "        except Exception as e:\n",
        "            corrupt_images.append(img_path)\n",
        "\n",
        "print(\"Corrupted images:\", len(corrupt_images))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaZjMk5NNo66"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "def show_duplicate_sets(duplicates, sets_to_display=3):\n",
        "    shown = 0\n",
        "    for hash_val, dup_paths in duplicates.items():\n",
        "        if shown >= sets_to_display:\n",
        "            break\n",
        "        print(f\"Duplicate set {shown + 1}:\")\n",
        "        plt.figure(figsize=(15, 4))\n",
        "        for i, img_path in enumerate(dup_paths):\n",
        "            try:\n",
        "                img = Image.open(img_path)\n",
        "                plt.subplot(1, len(dup_paths), i+1)\n",
        "                plt.imshow(img)\n",
        "                plt.title(os.path.basename(img_path))\n",
        "                plt.axis('off')\n",
        "            except:\n",
        "                continue\n",
        "        plt.show()\n",
        "        shown += 1\n",
        "\n",
        "show_duplicate_sets(duplicates, sets_to_display=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lukYiaeON1J"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "removed_count = 0\n",
        "\n",
        "for dup_list in duplicates.values():\n",
        "    # Keep the first, delete rest\n",
        "    for img_path in dup_list[1:]:\n",
        "        try:\n",
        "            os.remove(img_path)\n",
        "            removed_count += 1\n",
        "        except Exception as e:\n",
        "            print(f\"Error deleting {img_path}: {e}\")\n",
        "\n",
        "print(f\"✅ Removed {removed_count} duplicate images.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQoWFuAnOZ-3"
      },
      "outputs": [],
      "source": [
        "# Re-check to confirm duplicates removed\n",
        "hashes = defaultdict(list)\n",
        "\n",
        "for class_dir in class_dirs:\n",
        "    for img_file in os.listdir(os.path.join(repo_path, class_dir)):\n",
        "        img_path = os.path.join(repo_path, class_dir, img_file)\n",
        "        with open(img_path, 'rb') as f:\n",
        "            file_hash = hashlib.md5(f.read()).hexdigest()\n",
        "            hashes[file_hash].append(img_path)\n",
        "\n",
        "duplicates = {h: files for h, files in hashes.items() if len(files) > 1}\n",
        "print(\"🔁 Duplicates remaining:\", len(duplicates))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJjV-yQIOc-R"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "# Gather image info\n",
        "image_info = []\n",
        "\n",
        "for class_dir in class_dirs:\n",
        "    class_path = os.path.join(repo_path, class_dir)\n",
        "    for img_file in os.listdir(class_path):\n",
        "        img_path = os.path.join(class_path, img_file)\n",
        "        try:\n",
        "            with Image.open(img_path) as img:\n",
        "                width, height = img.size\n",
        "                image_info.append({\n",
        "                    'path': img_path,\n",
        "                    'width': width,\n",
        "                    'height': height,\n",
        "                    'class': class_dir\n",
        "                })\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "df_sizes = pd.DataFrame(image_info)\n",
        "\n",
        "# Define thresholds\n",
        "small_imgs = df_sizes[(df_sizes['width'] < 150) | (df_sizes['height'] < 150)]\n",
        "large_imgs = df_sizes[(df_sizes['width'] > 1000) | (df_sizes['height'] > 2000)]\n",
        "\n",
        "print(f\"🔻 Very small images: {len(small_imgs)}\")\n",
        "print(f\"🔺 Very large images: {len(large_imgs)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sr1ce3n5O4xb"
      },
      "outputs": [],
      "source": [
        "def show_images(df_subset, title, n=5):\n",
        "    plt.figure(figsize=(15, 3))\n",
        "    for i, (_, row) in enumerate(df_subset.head(n).iterrows()):\n",
        "        img = Image.open(row['path'])\n",
        "        plt.subplot(1, n, i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"{row['width']}x{row['height']}\")\n",
        "        plt.axis('off')\n",
        "    plt.suptitle(title)\n",
        "    plt.show()\n",
        "\n",
        "show_images(small_imgs, \"Very Small Images\")\n",
        "show_images(large_imgs, \"Very Large Images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSKKMxAwO8A3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Combine both sets\n",
        "outliers = pd.concat([small_imgs, large_imgs])\n",
        "\n",
        "# Remove them\n",
        "removed_count = 0\n",
        "for path in outliers['path']:\n",
        "    try:\n",
        "        os.remove(path)\n",
        "        removed_count += 1\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to remove {path}: {e}\")\n",
        "\n",
        "print(f\"🗑️ Removed {removed_count} outlier images (small + large).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sT18nP1yPkSM"
      },
      "outputs": [],
      "source": [
        "# Recalculate sizes\n",
        "image_info = []\n",
        "\n",
        "for class_dir in class_dirs:\n",
        "    class_path = os.path.join(repo_path, class_dir)\n",
        "    for img_file in os.listdir(class_path):\n",
        "        img_path = os.path.join(class_path, img_file)\n",
        "        try:\n",
        "            with Image.open(img_path) as img:\n",
        "                width, height = img.size\n",
        "                image_info.append({\n",
        "                    'path': img_path,\n",
        "                    'width': width,\n",
        "                    'height': height,\n",
        "                    'class': class_dir\n",
        "                })\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "df_sizes = pd.DataFrame(image_info)\n",
        "print(df_sizes[['width', 'height']].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1JuW9evPnm3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define parameters\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Augmentation and rescaling\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train_gen = datagen.flow_from_directory(\n",
        "    repo_path,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_gen = datagen.flow_from_directory(\n",
        "    repo_path,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOjjbp6PhU6Z"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "base_model = EfficientNetB0(include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), weights='imagenet')\n",
        "base_model.trainable = False  # Freeze base model\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(train_gen.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWtkFa4BiIBz"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=EPOCHS\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zg_d2TriOCu"
      },
      "outputs": [],
      "source": [
        "# Plot accuracy/loss curves\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Accuracy Over Epochs\")\n",
        "plt.show()\n",
        "\n",
        "# Save model\n",
        "model.save(\"tree_species_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fls9ZFbNnOPe"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define image properties\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Data generators\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    repo_path,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    repo_path,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Number of output classes\n",
        "num_classes = train_generator.num_classes\n",
        "\n",
        "# Build a basic CNN model\n",
        "model_cnn = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model_cnn.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "EPOCHS = 10\n",
        "history_cnn = model_cnn.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_generator\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model_cnn.save('basic_cnn_tree_species.h5')\n",
        "print(\"✅ Basic CNN model saved as 'basic_cnn_tree_species.h5'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yubJR58antIK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history_cnn.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history_cnn.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title(\"Basic CNN Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Y-tnHhWs4yK"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(30, activation='softmax')  # For 30 classes\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_generator, validation_data=val_generator, epochs=25)\n",
        "\n",
        "model.save(\"improved_cnn_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ea3ppubas5Dp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}